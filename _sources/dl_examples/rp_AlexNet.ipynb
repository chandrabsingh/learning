{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2187dd",
   "metadata": {},
   "source": [
    "# AlexNet Summary\n",
    "## Paper\n",
    "- ImageNet Classification with Deep Convolutional Neural Networks \n",
    "  - Authors: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (University of Toronto)\n",
    "  - NIPS 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc1d0b",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "> _\"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b7351",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Intro and Overview\n",
    "  - Alex was the one who started DL revolution\n",
    "  - so is the paper is also called as AlexNet\n",
    "  - first one to show it works on CUDA\n",
    "  - won competition by large margin\n",
    "  - vision earlier was done by hand\n",
    "  \n",
    "### The necessity of larger models\n",
    "  - traditionally\n",
    "    - small datasets like CIFAR of 32x32 pixels\n",
    "      - can be solved using classical computer vision model\n",
    "    - but for large datasets with higher resolution images\n",
    "      - was difficult to recognize\n",
    "      - ImageNet dataset is a large one\n",
    "        - 15 million high resolution images with 22000 categories\n",
    "  - large model is required\n",
    "    - to learn complexity of object recognition\n",
    "  - model must have lots of prior knowledge to compensate for all the data that is not available\n",
    "  - during this time, CNN was not popular\n",
    "    - was used to identify hand-written digits\n",
    "\n",
    "### Why CNNs\n",
    "  - convolutional operations have a strong prior \n",
    "  - and is consistent with object identification of computer vision\n",
    "    - _\"capacity can be controlled by varying their depth and breadth, and they also make strong and mostly correct assumptitons about the nature of images (namely, stationarity of statistics and locality of pixel dependencies)\"_\n",
    "  - one of problems they envisoned was \"overfitting\" with such large CNNs models\n",
    "  - also spoke about better results using CNNs and GPUs\n",
    "  - used many methods to prevent overfitting\n",
    "  - network size is limited by memory available on GPUs and permissible amount of training time \n",
    "\n",
    "### ImageNet\n",
    "  - Data\n",
    "    - ImageNet dataset is plenty\n",
    "      - 1.2 million training images\n",
    "      - 50000 validation images\n",
    "      - 150000 testing images\n",
    "      - 256x256 RGB size images\n",
    "      - 1000 images in each of 1000 category of classes\n",
    "      \n",
    "### Model Architecture Overview\n",
    "  - contains layers such as \n",
    "    - MaxPooling\n",
    "    - Dense layer\n",
    "    - increase the feature maps, in between, by decreasing the resolution\n",
    "  - split into 2 GPUs, with occasional inter-communication\n",
    "    - invention of bigger GPUs made it easier today\n",
    "    - no tensorflow was there back then\n",
    "\n",
    "<img src=\"./images/AlexNetModelArchitecture.png\" width=500 height=500>\n",
    "\n",
    "### ReLU Nonlinearities\n",
    "  - earlier mostly sigmoid or hyperbolic functions were used to model neuron function\n",
    "    - as it was differentiable\n",
    "  - the problem was no learning was achieved at boundaries\n",
    "    - _\" In terms of training time with gradient descent, these saturating nonlinearities are much slower than the non-saturating nonlinearity f(x) = max(0, x).\"_\n",
    "  - the ReLU trains much faster\n",
    "    - 6 times faster\n",
    "\n",
    "<img src=\"./images/AlexNet_ReLU.png\" width=200 height=500>\n",
    "\n",
    "### Multi-GPU training\n",
    "  - distributed a model onto 2 GPUs\n",
    "  - G-shard \n",
    "  - GPU interact with each other\n",
    "  - using 2 GPUs improved \n",
    "  - this is not what is used today with big GPUs\n",
    "\n",
    "### Classification Results\n",
    "  - was much better than the previous models\n",
    "  \n",
    "<img src=\"./images/AlexNet_result1.png\" width=200 height=300>\n",
    "  \n",
    "### Local Response Normalization\n",
    "  - normalize the response of ReLUs\n",
    "  - the denominator uses average of the layers infront and behind \n",
    "    - would it not be better just to take average of all\n",
    "      - because they wanted to capture the local effect\n",
    "    - or average of fixed group\n",
    "      - this is a question to think of\n",
    "  - inspired by _\"response normalization implements a form of lateral inhibition inspired by the type found in real neurons\"_\n",
    "  - inspired by _\"local contrast normalization scheme of Jarrett et al\"_\n",
    "  - ? How is Local Response Normalization different from Batch Normalization?\n",
    "  \n",
    "### Overlapping Pooling\n",
    "  - instead of pooling without overlap (as done today), they overlapped \n",
    "  \n",
    "### Architecture\n",
    "  - 224x224 with a stride of 4, with 3 channel maps\n",
    "  - this became 55x55 with 48 feature maps\n",
    "    - `feature maps keeps increasing`, while\n",
    "    - `dimension of image resolution keeps decreasing`\n",
    "  - stride of 4 used to downsample the image, at the same time as convolving it\n",
    "  - multiple dense layer at the end \n",
    "\n",
    "### Reducing overfitting\n",
    "  - today's deep model are mostly overfitted and we dont care about it\n",
    "    - _\"Our neural network architecture has 60 million parameters. Although the 1000 classes of ILSVRC make each training example impose 10 bits of constraint on the mapping from image to label, this turns out to be insufficient to learn so many parameters without considerable overfitting. Below, we describe the two primary ways in which we combat overfitting.\"_\n",
    "  - Data Augmentation\n",
    "    - random cropping and horizontal reflections\n",
    "      - both these data augmentation procedures are still used today\n",
    "      - to do image translations, random cropping is required\n",
    "    - _\"altering the intensities of the RGB channels in training images\"_\n",
    "      - PCA based image augmentation \n",
    "        - Is this still in use? Guess no\n",
    "### Dropout\n",
    "  - not used in today's model, mostly\n",
    "  - _\"Combining the predictions of many different models is a very successful way to reduce test errors\\[1, 3\\], but it appears to be too expensive for big neural networks that already take several days to train. \"_\n",
    "  - dropout\n",
    "    - _\"consists of setting to zero the output of each hidden neuron with probability 0.5\"_\n",
    "      - this method is still in use\n",
    "    - found dropout reduces overfitting\n",
    "\n",
    "### More Results\n",
    "  - use momentum to train this\n",
    "  - use ensemble methods using 1CNN, 5CNN and 7CNN\n",
    "  - use transfer learning\n",
    "    - _\"to classify the entire ImageNet Fall 2011 release (15M images, 22K categories), and then “fine-tuning” it on ILSVRC-2012 gives an error rate of 16.6%.\"_\n",
    "  - results are very good\n",
    "    - dalmation vs cherry\n",
    "  - nearest neighbors images are very close and relatable\n",
    "    - model learns variances across the class\n",
    "\n",
    "### Conclusion\n",
    "  - hasn't changed much today\n",
    "    - vs VGG16 or VGG19 is just depth\n",
    "    - vs ResNet - ?\n",
    "  - today we dont use 3 dense layers, \n",
    "    - simply use 1 dense layer and 1 classification layer\n",
    "  - mention that depth is important\n",
    "    - _\"It is notable that our network’s performance degrades if a single convolutional layer is removed\"_\n",
    "      - ResNets were ultra deep\n",
    "  - didnot use any unsupervised pre-training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
