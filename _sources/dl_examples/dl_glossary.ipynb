{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5722cd",
   "metadata": {},
   "source": [
    "# DL Conceptual brief\n",
    "\n",
    "## Libraries\n",
    "### TensorFlow\n",
    "- Google calls it **\"an open source software library for machine intelligence\"**\n",
    "- other deep learning libraries\n",
    "  - PyTorch (https://pytorch.org/), \n",
    "  - Caffe (https://caffe.berkeleyvision.org/), \n",
    "  - MxNet (https://mxnet.apache.org/)\n",
    "\n",
    "#### Features\n",
    "- have **auto-differentiation**, \n",
    "- support for CPU/GPU option, \n",
    "- have **pretrained models**, \n",
    "- support commonly used NN architectures like recurrent neural networks, convolutional neural networks, and deep belief networks\n",
    "- support for **eager computation** in TensorFlow 2.0, \n",
    "- support for **graph computation based on static graphs**\n",
    "- Keras – a high-level neural network API that has been **integrated with TensorFlow** (in 2.0, Keras became the standard API for interacting with TensorFlow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdd80c",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f3a90",
   "metadata": {},
   "source": [
    "### Keras\n",
    "- The core layers in Keras includes dense layers, activation layers, and dropout layers. There are other layers that are more complex, including convolutional layers and pooling layers\n",
    "- A dense layer is also known as a fully-connected layer. It is fully-connected because it uses all of its input (as opposed to a subset of the input) for the mathematical function that it implements.\n",
    "- A dense layer implements the following function:\n",
    "\n",
    "$$\\hat{y} = \\sigma(Wx + b)$$\n",
    "\n",
    "  - where $\\hat{y}$ is the output, $\\sigma$ is the activation function, $x$ is the input, and $W$ and $b$ are the weights and biases respectively.\n",
    "- A model is a collection of layers\n",
    "- Loss function – error metric for neural network training\n",
    "\n",
    "<img src=\"https://www.oreilly.com/library/view/neural-network-projects/9781789138900/assets/081fd69c-7a42-4394-a198-a533a7e2892d.png\">\n",
    "\n",
    "- A linear classifier can solve the AND and OR problems but is not able to solve the XOR\n",
    "- https://dev.to/jbahire/demystifying-the-xor-problem-1blk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cedeb6",
   "metadata": {},
   "source": [
    "## General concepts\n",
    "### Perceptron algorithm\n",
    "### Softmax algorithm\n",
    "\n",
    "### Transfer Learning\n",
    "- Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.\n",
    "- How do you make an image classifier that can be trained in a few minutes on a CPU with very little data?\n",
    "  - Use pre-trained models, i.e., models with known weights\n",
    "\n",
    "### Representation Learning\n",
    "\n",
    "### Activation function\n",
    "### ReLU\n",
    "\n",
    "### Back propagation\n",
    "- Gradients are important\n",
    "  - If it's differentiable, we can probably learn on it\n",
    "- Gradients can vanish\n",
    "  - Each additional layer can successively reduce signal vs. noise, when layers become deep\n",
    "  - ReLUs are useful here\n",
    "  - Try to limit depth of model\n",
    "- Gradients can explode\n",
    "  - can get NaNs\n",
    "  - Learning rates are important here\n",
    "    - try lower learning rate\n",
    "  - Batch normalization (useful knob) can help\n",
    "- ReLu layers can die\n",
    "  - Keep calm and lower your learning rates\n",
    "\n",
    "### Forward propagation\n",
    "\n",
    "### Training Neural Nets\n",
    "#### Normalizing Feature Values\n",
    "  - features must have reasonable scales\n",
    "    - Roughly zero-centered, \\[-1, 1\\] range often works well\n",
    "    - Helps gradient descent converge; avoid NaN trap\n",
    "    - Avoiding outlier values can also help\n",
    "  - Can use a few standard methods\n",
    "    - Linear scaling\n",
    "    - Hard cap (clipping) to max, min\n",
    "    - Log scaling\n",
    "\n",
    "#### Dropout Regularization\n",
    "- Dropout: Another form of regularization, useful for NNs\n",
    "  - Works by randomly \"dropping out\" units in a network for a single gradient step\n",
    "    - There's a connection to ensemble models here\n",
    "  - The more you drop out, the stronger the regularization\n",
    "    - 0.0 = no dropout regularization\n",
    "    - 1.0 = drop everything out! learns nothing\n",
    "    - Intermediate values more useful\n",
    "\n",
    "\n",
    "### Cross Entropy\n",
    "### Encoder-Decoder\n",
    "\n",
    "### Neural Style Transfer \n",
    "- is the technique of blending style from one image into another image keeping its content intact. The only change is the style configurations of the image to give an artistic touch to your image.\n",
    "\n",
    "### Content Loss\n",
    "### Style Loss\n",
    "### Gram Matrices\n",
    "\n",
    "### Multi-Class Neural Nets\n",
    "#### One-Vs-All Multi-Class \n",
    "  - SoftMax Multi-Class\n",
    "    - Add an additional constraint: Require output of all one-vs-all nodes to sum to 1.0\n",
    "    - use logits that sums to 1\n",
    "    - The additional constraint helps training converge quickly\n",
    "    - Plus, allows outputs to be interpreted as probabilities\n",
    "    \n",
    "#### Multi-Class, Single-Label Classification:\n",
    "  - An example may be a **member of only one class.**\n",
    "  - Constraint that classes are **mutually exclusive** is helpful structure.\n",
    "  - Useful to encode this in the loss.\n",
    "  - Use **one softmax loss for all possible classes.**\n",
    "  \n",
    "#### Multi-Class, Multi-Label Classification:\n",
    "  - An example may be a **member of more than one class.**\n",
    "  - No additional constraints on class membership to exploit.\n",
    "  - **One logistic regression loss for each possible class.**\n",
    "  - **Multiple logistic regression**\n",
    "\n",
    "### SoftMax Options\n",
    "#### Full SoftMax\n",
    "- For Multi-Class classification problems\n",
    "  - Brute force; calculates for all classes.\n",
    "- DisAdv\n",
    "  - relatively expensive to train\n",
    "  - for million classes, million output nodes needs to be trained, for every single example\n",
    "  \n",
    "#### Candidate Sampling\n",
    "- allows to be more efficient by differentiating between classes\n",
    "  - for labrador/pup, we can easily differentiate it with a toaster\n",
    "- Calculates for all the positive labels, but only for a random sample of negatives.\n",
    "  - is more efficient\n",
    "\n",
    "\n",
    "### Local Response Normalization vs Batch Normalization\n",
    "- https://towardsdatascience.com/difference-between-local-response-normalization-and-batch-normalization-272308c034ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e52f48",
   "metadata": {},
   "source": [
    "## 10 most popular deep learning algorithms\n",
    "[Link](https://www.simplilearn.com/tutorials/deep-learning-tutorial/deep-learning-algorithm)\n",
    "\n",
    "### Convolutional Neural Networks (CNNs)\n",
    "- Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a **Convolutional Neural Network(ConvNet/CNN)**.\n",
    "- Neural networks came to prominence in **2012** as machine learning expert **Alex Krizhevsky** utilized them to get **first prize in the ImageNet competition**.\n",
    "- Applications\n",
    "  - Facebook’s famous automatic tagging algorithm works? The answer is neural networks.\n",
    "  - product recommendation you get on Amazon and several other similar platforms is because of neural networks.\n",
    "  - Neural networks are the reason behind Google’s superb image searching abilities.\n",
    "  - Instagram’s solid search infrastructure is possible because the social media network uses neural networks.\n",
    "- A convolutional network **ingests such images** as three separate strata of color **stacked one on top of the other**. A normal color image is seen as a rectangular box whose width and height are measured by the number of pixels from those dimensions. The depth layers in the three layers of colours(RGB) interpreted by CNNs are referred to as channels.\n",
    "- A ConvNet is able to successfully **capture the Spatial and Temporal dependencies** in an image through the application of relevant filters. \n",
    "- The **role of the ConvNet** is to **reduce the images** into a form which is easier to process, **without losing features** which are critical for getting a good prediction.\n",
    "- The objective of the Convolution Operation is to **extract the high-level features** such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer. Conventionally, the **first ConvLayer** is responsible for **capturing the Low-Level features** such as edges, color, gradient orientation, etc.\n",
    "- CNN's have a **ReLU layer** to **perform operations on elements**. The output is a rectified feature map.\n",
    "- the **Pooling layer** is responsible for **reducing the spatial size of the Convolved Feature**. This is to **decrease the computational power required to process the data through dimensionality reduction**. Furthermore, it is useful for **extracting dominant features which are rotational and positional invariant**, thus maintaining the process of effectively training of the model.\n",
    "- **Adding a Fully-Connected layer** is a (usually) **cheap way of learning non-linear combinations of the high-level features** as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.\n",
    "- There are **various architectures of CNNs available** which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:\n",
    "  - LeNet\n",
    "  - AlexNet\n",
    "  - VGGNet\n",
    "  - GoogLeNet\n",
    "  - ResNet\n",
    "  - ZFNet\n",
    "- https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "#### General Concepts\n",
    "##### Convolution\n",
    "##### Max Pooling\n",
    "##### Average Pooling\n",
    "##### Fully Connected\n",
    "##### SOTA Models\n",
    "##### Differential Learning Rate\n",
    "##### Feature Maps\n",
    "##### Kernel\n",
    "##### Filter\n",
    "##### Spatial information\n",
    "##### local receptive fields, shared weights, and pooling\n",
    "##### Strides\n",
    "##### Convolution2D, MaxPooling2D\n",
    "##### Padding\n",
    "##### Flatten Layer\n",
    "##### Pooling layers\n",
    "\n",
    "\n",
    "\n",
    "##### Convolutional Layer\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*qtinjiZct2w7Dr4XoFixnA.gif\">\n",
    "\n",
    "\n",
    "##### CNN sequence to classify handwritten digits\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\">\n",
    "\n",
    "\n",
    "##### Flattened 3x3 image matrix 1 dimension\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/850/1*GLQjM9k0gZ14nYF0XmkRWQ.png\" width=500 height=500>\n",
    "\n",
    "\n",
    "##### Kernel \n",
    "\n",
    "- Convoluting a 5x5x1 image(Green) with a 3x3x1 kernel(Yellow) to get a 3x3x1(Red) convolved feature\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1052/1*GcI7G-JLAQiEoCON7xFbhg.gif\" width=500 height=500>\n",
    "\n",
    "\n",
    "- Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif\">\n",
    "\n",
    "\n",
    "- Convolution Operation with Stride Length = 2\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/790/1*1VJDP6qDY9-ExTuQVEOlVg.gif\" width=500 height=500>\n",
    "\n",
    "\n",
    "- SAME padding: 5x5x1 image is padded with 0s to create a 6x6x1 image\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/790/1*nYf_cUIHFEWU1JXGwnz-Ig.gif\" width=500 height=500>\n",
    "\n",
    "\n",
    "##### Types of Pooling \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1192/1*KQIEqhxzICU7thjaQBfPBQ.png\" width=500 height=500>\n",
    "\n",
    "\n",
    "##### Fully Connected Layer (FC Layer)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*kToStLowjokojIQ7pY2ynQ.jpeg\" width=500 height=500>\n",
    "\n",
    "\n",
    "\n",
    "- https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "- https://github.com/ss-is-master-chief/MNIST-Digit.Recognizer-CNNs/blob/master/MNIST-Hand.Written.Digit.Recognition-CNN.ipynb\n",
    "- https://medium.datadriveninvestor.com/introduction-to-how-cnns-work-77e0e4cde99b\n",
    "\n",
    "\n",
    "#### CNN Research Papers\n",
    "\n",
    "\n",
    "##### ResNet\n",
    "- Deep Residual Learning for Image Recognition\n",
    "\n",
    "##### VGG\n",
    "- Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "\n",
    "##### DenseNet\n",
    "- Densely Connected Convolutional Networks\n",
    "- A DenseNet is a type of convolutional neural network that utilises dense connections between layers, through Dense Blocks, where we connect all layers (with matching feature-map sizes) directly with each other. To preserve the feed-forward nature, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers.\n",
    "\n",
    "##### AlexNet\n",
    "- ImageNet Classification with Deep Convolutional Neural Networks\n",
    "\n",
    "##### VGG-16\n",
    "- Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "- https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "##### MobileNetV2\n",
    "- MobileNetV2: Inverted Residuals and Linear Bottlenecks\n",
    "\n",
    "##### EfficientNet\n",
    "- EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\n",
    "\n",
    "##### Darknet-53\n",
    "- YOLOv3: An Incremental Improvement\n",
    "\n",
    "##### ResNeXt\n",
    "- Aggregated Residual Transformations for Deep Neural Networks\n",
    "\n",
    "##### GoogLeNet\n",
    "- Going Deeper with Convolutions\n",
    "\n",
    "##### Xception\n",
    "- Xception: Deep Learning With Depthwise Separable Convolutions\n",
    "\n",
    "##### SqueezeNet\n",
    "- SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\n",
    "\n",
    "##### Inception-v3\n",
    "- Rethinking the Inception Architecture for Computer Vision\n",
    "\n",
    "##### CSPDarknet53\n",
    "- YOLOv4: Optimal Speed and Accuracy of Object Detection\n",
    "\n",
    "#### CNN Applications\n",
    "##### General Classification\n",
    "##### Image Classification\n",
    "##### Semantic Segmentation\n",
    "- Classify Each Pixel\n",
    "- Fully-Convolutional Networks\n",
    "- SegNet & U-NET\n",
    "- Faster R-CNN linked to Semantic Segmentation: Mask R-CNN\n",
    "\n",
    "##### Object Detection \n",
    "##### Quantization \n",
    "##### Computed Tomography (CT) \n",
    "##### Domain Adaptation \n",
    "##### Out-of-Distribution Detection \n",
    "##### Language Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b0759",
   "metadata": {},
   "source": [
    "### Long Short Term Memory Networks (LSTMs)\n",
    "\n",
    "### Recurrent Neural Networks (RNNs)\n",
    "- **Recurrent Neural Networks (RNNs)** are widely used for data with some kind of **sequential structure**. For instance, **time series data has an intrinsic ordering based on time**. Sentences are also sequential, “I love dogs” has a different meaning than “Dogs I love.” Simply put, if the **semantics of your data is altered by random permutation, you have a sequential dataset and RNNs may be used for your problem!** To help solidify the types of problems RNNs can solve, here is a list of common applications :\n",
    "- **Applications**\n",
    "  - Speech Recognition\n",
    "  - Sentiment Classification\n",
    "  - Machine Translation (i.e. Chinese to English)\n",
    "  - Video Activity Recognition\n",
    "  - Name Entity Recognition — (i.e. Identifying names in a sentence)\n",
    "- What are RNNs\n",
    "  - RNNs are **different than the classical multi-layer perceptron (MLP) networks** because of two main reasons: \n",
    "    - 1) They take into account what happened previously and \n",
    "    - 2) they share parameters/weights.\n",
    "  - A recurrent neural network is a neural network that is specialized for processing a sequence of data x(t)= x(1), . . . , x(τ) with the time step index t ranging from 1 to τ. For tasks that involve sequential inputs, such as speech and language, it is often better to use RNNs. In a NLP problem, if you want to predict the next word in a sentence it is important to know the words before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far.\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "\n",
    "- https://pub.towardsai.net/whirlwind-tour-of-rnns-a11effb7808f\n",
    "- https://towardsdatascience.com/recurrent-neural-networks-rnns-3f06d7653a85\n",
    "- https://github.com/javaidnabi31/RNN-from-scratch/blob/master/RNN_char_text%20generator.ipynb\n",
    "- https://www.deeplearningbook.org/contents/rnn.html\n",
    "- https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "- https://www.coursera.org/learn/nlp-sequence-models/lecture/0h7gT/why-sequence-models\n",
    "- [A Gentle Tutorial of Recurrent Neural Network with Error Backpropagation](https://arxiv.org/pdf/1610.02583.pdf)\n",
    "\n",
    "\n",
    "\n",
    "#### Evolution of R-CNN\n",
    "- Region based CNN\n",
    "- Fast R-CNN\n",
    "- Faster R-CNN\n",
    "\n",
    "#### Fully-Convolutional Networks (FCN)\n",
    "#### RNN vs CNN\n",
    "- Type of Data\n",
    "  - CNNs are used in solving problems related to spatial data, such as images. \n",
    "  - RNNs are better suited to analyzing temporal, sequential data, such as text or videos.\n",
    "- Architecture\n",
    "  - CNNs are \"feed-forward neural networks\" that use filters and pooling layers, \n",
    "  - RNNs feed results back into the network \n",
    "- Size of input\n",
    "  - CNNs have fixed size of the input and the resulting output are fixed. \n",
    "  - In RNNs size of input and its resulting output may vary\n",
    "- Use cases \n",
    "  - CNNs include facial recognition, medical analysis and classification\n",
    "  - RNNs include text translation, NLP, sentiment analysis and speech analysis\n",
    "\n",
    "#### U-NET \n",
    "- Long Skip Connections\n",
    "\n",
    "#### Model Compression\n",
    "##### Knowledge distillation\n",
    "##### Pruning\n",
    "##### Quantization\n",
    "##### Low-rank approximation and sparsity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545bb0f",
   "metadata": {},
   "source": [
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "\n",
    "### Radial Basis Function Networks (RBFNs)\n",
    "\n",
    "### Multilayer Perceptrons (MLPs)\n",
    "\n",
    "### Self Organizing Maps (SOMs)\n",
    "\n",
    "### Deep Belief Networks (DBNs)\n",
    "\n",
    "### Restricted Boltzmann Machines( RBMs)\n",
    "\n",
    "### Autoencoders\n",
    "\n",
    "\n",
    "## Optimization algorithms - Deep Learning\n",
    "- [Optimizing GD](https://ruder.io/optimizing-gradient-descent/)\n",
    "- [Optimizer Visualization](https://github.com/Jaewan-Yun/optimizer-visualization)\n",
    "\n",
    "### ASGD\n",
    "### Adadelta\n",
    "### Adagrad\n",
    "### Adam\n",
    "### AdamW\n",
    "### Adamax\n",
    "### LBFGS\n",
    "### NAdam\n",
    "### RAdam\n",
    "### RMSprop\n",
    "### Rprop\n",
    "### SGD\n",
    "### SparseAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aee738",
   "metadata": {},
   "source": [
    "## Artificial neural network\n",
    "- https://towardsdatascience.com/neural-network-architectures-156e5bad51ba\n",
    "\n",
    "\n",
    "### Autoencoder\n",
    "### Cognitive computing\n",
    "### Deep learning\n",
    "### DeepDream\n",
    "\n",
    "### Multilayer perceptron\n",
    "A **perceptron** was the name given to a model having one single linear layer and, if it has multiple layers, it is  called a **multi-layer perceptron (MLP)**. Note that the input and the output layers are visible from outside, while all the other layers in the middle are hidden – hence the name hidden layers. In this context, a single layer is simply a linear function and the MLP is therefore obtained by stacking multiple single layers one after the other:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Hassan-Afzaal/publication/338103191/figure/fig2/AS:838599264174093@1576949053675/The-multilayer-perceptron-MLP-model-for-various-input-variable-combinations.jpg\" width=500 height=500>\n",
    "\n",
    "### RNN \n",
    "#### LSTM\n",
    "#### GRU\n",
    "#### ESN\n",
    "### Restricted Boltzmann machine\n",
    "### GAN\n",
    "### SOM\n",
    "### Convolutional neural network \n",
    "#### U-Net\n",
    "### Transformer Vision\n",
    "### Spiking neural network\n",
    "### Memtransistor\n",
    "### Electrochemical RAM (ECRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b47462",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "- Background Subtraction\n",
    "- Colorspace\n",
    "- Features\n",
    "- Filters\n",
    "- Geometry\n",
    "- Affine transforms\n",
    "- Projective transforms\n",
    "- HOG Features\n",
    "- Histograms\n",
    "- Homography\n",
    "- Hough Transform\n",
    "- Image Gradients\n",
    "- K-Means\n",
    "- Kalman Filter\n",
    "- Linear algebra\n",
    "- Vectors\n",
    "- Matrices\n",
    "- Morphological Operations\n",
    "- Optical Flow\n",
    "- Segmentation\n",
    "- Thresholding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d4cda",
   "metadata": {},
   "source": [
    "## Intro to Deep Learning - Lectures\n",
    "\n",
    "- Lecture 1 - Intro to Deep Learning\n",
    "- Lecture 2 - Deep Sequence Modeling\n",
    "- Software Lab 1 - Intro to TensorFlow; Music Generation\n",
    "- Lecture 3 - Deep Computer Vision\n",
    "- Lecture 4 - Deep Generative Modeling\n",
    "- Software Lab 2 - De-biasing Facial Recognition Systems\n",
    "- Lecture 5 - Deep Reinforcement Learning\n",
    "- Lecture 6 - Limitations and New Frontiers\n",
    "- Software Lab 3 - Learning End-to-End Self-Driving Control\n",
    "- Lecture 7 - Autonomous Driving with LiDAR\n",
    "- Lecture 8 - Uncertainty in Deep Learning\n",
    "- Lecture 9 - AI 4 Science\n",
    "- Lecture 10 - Speech Recognition\n",
    "- Final Project\n",
    "- Project Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e91661",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
