{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72207836",
   "metadata": {},
   "source": [
    "# ResNet Summary\n",
    "\n",
    "## Paper\n",
    "- Deep Residual Learning for Image Recognition\n",
    "  - Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (Microsoft Research)\n",
    "  - ILSVRC 2015\n",
    "\n",
    "## Abstract\n",
    "> _\"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8×deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers._\n",
    "\n",
    "> _The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5829b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Intro and Overview\n",
    "- Prior to this paper, everyone tried making bigger networks\n",
    "  - because accuracy on ImageNet increased with bigger networks\n",
    "- reached to the limit of making bigger networks\n",
    "- This paper was a revolution \n",
    "- after this residual connection became a norm\n",
    "- this is now used in\n",
    "  - image recognition\n",
    "  - transformers\n",
    "  \n",
    "\n",
    "### The Problem with Depth\n",
    "- the norm was if depth of NN is increased\n",
    "  - it performs better\n",
    "  - it generalizes better\n",
    "  - reaches lower training loss\n",
    "    - but optimizing it was hard\n",
    "- generally there would be drop in learning rate and would reach a lower level\n",
    "  - but if on further increasing the depth, \n",
    "    - training error would increase, both for training and test error\n",
    "- this was not a problem of overfitting, \n",
    "  - as training error is not increasing after it came down with increase of iterations\n",
    "\n",
    "<img src=\"./images/ResNet_01_ProblemWithDepth.png\">\n",
    "\n",
    "### VGG-Style Networks\n",
    "- VGG nets were popular network earlier\n",
    "  - An image would be input to convolutional layers\n",
    "    - at first the layer will have a big resolution but with lower channel size\n",
    "    - then image resolution would be downscaled, with an increase in number of filter\n",
    "    - so more and more filters will be stacked, as resolution is down scaled\n",
    "      - why?\n",
    "      - in image classification\n",
    "        - at lower level  \n",
    "          - edges are parsed\n",
    "        - at higher level  \n",
    "          - NN learns more of abstract features\n",
    "            - why?\n",
    "              - at higher levels, the exact localization of these features will be less and less important\n",
    "              - so if a car is present in the image,\n",
    "              - its not that important where it is\n",
    "                - for car\n",
    "                  - lower levels will recognize the edges\n",
    "                  - intermediate levels will recognize the geometric shapes of wheel and body\n",
    "                  - higher levels will learn to combine the individual parts of each other\n",
    "        - at higher levels, its more important to build more expressive features\n",
    "        - so the resolution was downscaled and number of filters were upscaled\n",
    "    - this was a good hypothesis/heuristic\n",
    "- the question was \n",
    "  - why does it gets worse if layers are added\n",
    "\n",
    "### Overfitting is not the Problem\n",
    "> _\"Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in and thoroughly verified by our experiments.\"_\n",
    "\n",
    "> _\"The degradation (of training accuracy) indicates that not all systems are similarly easy to optimize. Let us consider a shallower architecture and its deeper counterpart that adds more layers onto it. There exists a solution by construction to the deeper model: the added layers are identity mapping, and the other layers are copied from the learned shallower model. The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart\"_\n",
    "\n",
    "- In a shallow model, like 5 layers that learns a particular function \n",
    "  - then there also exists another deep model that learns the same function by copying over these 5 layers and also have another 5 layers which are basically identity function (10 layers)\n",
    "  - so if 5 layer network can be learned, that implies we can also train the 10 layer network with the same accuracy\n",
    "  - why because the additional 5 layers can simply learn the identity function\n",
    "\n",
    "\n",
    "### Motivation for Residual Connections\n",
    "- so why is the identity function not learned?\n",
    "  - because we initially initialize the zero weights (from a Gaussian distribution of some standard deviation but with a mean of zero)\n",
    "  - furthermore, the regularization or weight decay like L2, they bias the weight towards zero\n",
    "  - this implies that these network function learn the zero function really well\n",
    "    - learning identity function is as difficult as any other function\n",
    "  - in convolution network 3x3 filter, the identity function, 9 weights need to be learned\n",
    "- so the paper tries to find,\n",
    "  - can the not use the zero weights function \n",
    "$$X \\rightarrow \\text{learn from NN} \\rightarrow \\tilde{X}$$\n",
    "  - instead use the default function as the identity function\n",
    "    - let X stay the X and then learn whatever we need to change\n",
    "    - X is a good default to not change much\n",
    "$$X \\rightarrow \\tilde{X} + \\text{\"some deviation that needs to be learned\"}$$\n",
    "- the hypothesis that paper talks about is \n",
    "  - by increasing the network layer, not much is learnt\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2298fff",
   "metadata": {},
   "source": [
    "### Residual Blocks\n",
    "\n",
    "<img src=\"./images/ResNet_02_Overfitting.png\">\n",
    "\n",
    "- The paper talks about having skip connections\n",
    "- Say there is a function $H(x) := F(x) + x$\n",
    "  - so whatever we meed to change about x\n",
    "  - or whatever we wnat the input to be changed to output\n",
    "    - the weight layer tend towards the zero function\n",
    "    - so if $F(x)$ tends towards zero function, then $H(x)$ becomes identity function\n",
    "      - so the default function of this network is identity function\n",
    "      - and what we learn is how to deviate from the identity function, which is a default function\n",
    "- at the bottom we see there is a relu function, which implies the total network is nonlinear function in total\n",
    "  - but the default is the identity function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff068248",
   "metadata": {},
   "source": [
    "\n",
    "### From VGG to ResNet\n",
    "- if these networks are chained, we get a residual network\n",
    "\n",
    "<img src=\"./images/ResNet_03_VGG_to_ResNet.png\">\n",
    "\n",
    "- In VGG-19 network,\n",
    "  - initially, image has 4 channels\n",
    "    - upscale it to 64 channels and have resolution of 224\n",
    "  - then use maxpools \n",
    "    - which 1/2's the resolution to 112, but up the filters to 128\n",
    "  - then use maxpools again\n",
    "    - which 1/2's the resolution to 56, but up the filters to 256\n",
    "  - this network has lot of parameters\n",
    "    - needs lot of computation 19.6 billion FLOPs(floating point operations) for a forward pass\n",
    "- In residual network,\n",
    "  - the network has lot less parameters/complexity compared to VGG\n",
    "    - 3.6 billion FLOPs\n",
    "  - it is still much deeper\n",
    "  - trade-off\n",
    "    - not that many parameters are needed\n",
    "    - succession of layers makes it learn lot more than having massive layers\n",
    "    - ResNets have much less amount of filters 64 compared to 256\n",
    "    \n",
    "<img src=\"./images/ResNet_04_VGG_to_ResNet_filters.png\">\n",
    "\n",
    "- they also make a 34 layer network called plain \n",
    "  - with no pooling, but use stride to convolution(instead of maxpool or average pooling) to downscale\n",
    "  \n",
    "- The paper first compares VGG19 to 34 layer plain\n",
    "  - we see that we loose performance, when the number of layers are increased\n",
    "- then it compares it to 34 layer plain to residual network\n",
    "  - no extra parameters are introduced here, the only difference \n",
    "  - is it has the jumping/skip connections\n",
    "    - the signal can travel as the identity function\n",
    "  - the network becomes trainable\n",
    "    - and deeper network better network\n",
    "  - caveat is\n",
    "    - output has to be of the same size as input\n",
    "      - as input needs to be added onto the output\n",
    "    - for example here the output is half the size of input, but the number of filter size is double\n",
    "    - it projects 64 filters to 128 filters\n",
    "    \n",
    "<img src=\"./images/ResNet_06_VGG_to_ResNet_residual.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fa670",
   "metadata": {},
   "source": [
    "### Experimental Results\n",
    "- On left hand side figure,\n",
    "  - 18 layer network has lower train and validation accuracy\n",
    "  - the solid line is the validation error of the center crops\n",
    "  - the training error will be higher, as they do different augmentation\n",
    "  - the training and validation error is higher in the deeper network(34 layer), if residual connection is not used\n",
    "    - this is not due to overfitting\n",
    "    - this is because the deeper network cannot be trained\n",
    "      - the solution space of 18 layer is a subspace of solution space of 34 layer\n",
    "      - we should be able to train equivalent to or lower than the accuracy of 18 layers\n",
    "        - but we can't\n",
    "- On right hand side figure, in the residual connection\n",
    "  - trend is exactly reversed\n",
    "    - 34 layer has much better training and validation error than thee 18 layer\n",
    "      - with 18 layers, the residual network error is marginally better in plain network\n",
    "      - with 34 layers, the residual network error is lot better compared to plain network\n",
    "        - residual connection help more and more, the deeper the network is \n",
    "        - more importantly, residual networks don't degrade the shallower network\n",
    "        \n",
    "<img src=\"./images/ResNet_07_ExpResults_training.png\" width=400 height=400>\n",
    "\n",
    "<img src=\"./images/ResNet_08_ExpResults_result.png\" width=400 height=400>\n",
    "\n",
    "\n",
    "- the paper also compares the error with other networks\n",
    "  - ResNet-34 A\n",
    "    - zero padding of projection\n",
    "  - ResNet-34 B\n",
    "    - having projections simply between where channels don't fit\n",
    "    - gives a quite a bit of boost\n",
    "  - ResNet-34 C\n",
    "    - having projections in every single residual connection \n",
    "    - does not give that much of a boost and introduces many more parameters\n",
    "    \n",
    "- the paper also experiments deeper layer ResNets\n",
    "  - among ResNet-50, ResNet-101, ResNet-152\n",
    "    - ResNet-152 was the best one and also implied that more depth to have better network\n",
    "  - they made an ensemble of different models and won 2015 ImageNet competition\n",
    "\n",
    "<img src=\"./images/ResNet_09_ExpResults_comparison1.png\" width=400 height=400>\n",
    "\n",
    "<img src=\"./images/ResNet_10_ExpResults_comparison2.png\" width=400 height=400>\n",
    "\n",
    "<img src=\"./images/ResNet_11_ExpResults_comparison3.png\" width=400 height=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f5f36",
   "metadata": {},
   "source": [
    "### Bottleneck Blocks\n",
    "\n",
    "- the paper introduced bottleneck blocks\n",
    "  - on left hand side image\n",
    "    - for 64 dimension image, \n",
    "    - it used 64 feature channels in convolution \n",
    "    - and had 64 dimension output\n",
    "  - on right hand side image\n",
    "    - for 256 dimension image, \n",
    "    - can save computation power, by projecting down to 64 first\n",
    "    - as the complexity of \"3x3, 64\" layer will be the same as left hand network layer\n",
    "    - and then project up again\n",
    "    - 1x1 convolution is significantly lower computational intensive than the 3x3 convolution\n",
    "    - its 9 times less operation \n",
    "    \n",
    "<img src=\"./images/ResNet_12_BottleneckBlocks_comparison.png\" width=400 height=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f329c0",
   "metadata": {},
   "source": [
    "### Deeper ResNets\n",
    "- this model is still used as pretrained version\n",
    "- used in segmentation applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
