{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9f3104",
   "metadata": {},
   "source": [
    "# Lecture 1 - Introduction\n",
    "\n",
    "## Topics\n",
    "- Introduction\n",
    "- Examples\n",
    "- Solving Optimization Problems\n",
    "- Least-Squares\n",
    "- Linear Programming\n",
    "- Convex Optimizations\n",
    "- How To Solve? \n",
    "- Course Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753a55d",
   "metadata": {},
   "source": [
    "## Mathematical optimization\n",
    "> minimize $f_{0}(x)$  \n",
    "> subject to $f_{i}(x) \\le b_{i}, \\space \\space i = 1,..,m$  \n",
    "- optimization variables $x = (x_{1},.., x_{n})$\n",
    "- objective function $f_{0}$\n",
    "- constraint functions $f_{i}$\n",
    "- optimal solution - $x^{*}$ has smallest value of $f_{0}$ among all vectors that satisfy the constraints\n",
    "\n",
    "- Examples\n",
    "  - portfolio optimization\n",
    "    - variables - amounts invested in different assets\n",
    "    - constraints - minimum return per asset\n",
    "    - objective - overall risk or return variance\n",
    "  - data fitting\n",
    "    - variables - model parameters\n",
    "    - constraints - prior information, parameter limits\n",
    "    - objective - prediction error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1f268",
   "metadata": {},
   "source": [
    "## Solving optimization problem\n",
    "- general optimization problem\n",
    "  - generally speaking - global solution is hard to find\n",
    "  - methods involve compromise\n",
    "- type of problems that can be solved\n",
    "  - least square problems\n",
    "  - linear programming problems (most of them)\n",
    "  - convex optimization problems (we can find global solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c302d",
   "metadata": {},
   "source": [
    "## Least-squares\n",
    "> minimize $\\| Ax - b\\|^{2}_{2}$\n",
    "- analytical solution $x^{*} = (A^{T}A)^{-1}A^{T}b$\n",
    "- computation time proportional to $n^{2}k (A \\in R^{kxn})$\n",
    "- n is the number of dimension, which is small\n",
    "- k is the number of rows in A, which is big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f31d62",
   "metadata": {},
   "source": [
    "## Linear programming\n",
    "\n",
    "> minimize $c^{T}x$  \n",
    "> subject to $a_{i}^{T}x \\le b_{i}, \\space \\space i = 1,..,m$  \n",
    "- computation time proportional to $n^{2}m \\text{( if }m \\ge n)$\n",
    "  - small dimension square times a large dimension\n",
    "- m is the number of constraints \n",
    "- k is the height of A\n",
    "- there are many problems that does not look like linear program but can be transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6ac26",
   "metadata": {},
   "source": [
    "## Convex optimization problem\n",
    "\n",
    "> minimize $f_{0}(x)$  \n",
    "> subject to $f_{i}(x) \\le b_{i}, \\space \\space i = 1,..,m$  \n",
    "- convex means graph should have positive curvature\n",
    "- function $f_{0}(x)$(objective) and $f_{1}(x)$(constraint) have to be convex\n",
    "> $f_{i}(\\alpha x + \\beta y) \\le \\alpha f_{i}(x) + \\beta f_{i}(y) $  \n",
    ">> if $\\alpha + \\beta = 1, \\alpha \\ge 0, \\beta \\ge 0$ \n",
    "  - affine functions make this equality\n",
    "  - convex functions have non-negative curvature\n",
    "  - affine functions have zero curvature. They are right at the boundary\n",
    "- least squares problem have convex form\n",
    "  - the least square objective plot is a quadratic function\n",
    "  - looks like a bowl\n",
    "  - a slice at a level will be ellipsoid\n",
    "- linear programming is also convex problem\n",
    "  - all of its objective is linear\n",
    "  - linear functions are right on the boundary\n",
    "  - they have zero curvature\n",
    "- one way to say convex is just positive curvature\n",
    "- there are no analytical solutions\n",
    "- but they have efficient algorithms\n",
    "- we get solutions\n",
    "- computation time  (roughly) proportional to max $\\{n^{3}, n^{2}m, F\\}$, where F is cost of evaluating $f_{i}$'s and their first and second derivatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c865830",
   "metadata": {},
   "source": [
    "- Other form of the convex problem can be:\n",
    "> $f_{i}(\\theta x + (1-\\theta) y) \\le \\theta f_{i}(x) + (1-\\theta) f_{i}(y) $  \n",
    ">> for $\\theta \\in [0,1]$\n",
    "- $\\alpha,\\beta$ problem the function will be called sublinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f0e89",
   "metadata": {},
   "source": [
    "## Problem\n",
    "- there are bunch of lights illuminating a surface which is piece wise linear\n",
    "- mapping between power and illumination is linear\n",
    "  - the light is incoherent and the power adds up\n",
    "> $I_k = \\sum\\limits_{j=1}^{m}a_{kj}p_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379d023",
   "metadata": {},
   "source": [
    "## Read\n",
    "- NP hard problems\n",
    "- rank two approximation of matrix - is a non-convex problem\n",
    "- problems that have no constrain - unconstrained problems\n",
    "- problems with no objective - feasibility problem or satisfaction problems\n",
    "- combinatorial problems - non-convex problems\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
