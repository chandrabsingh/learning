{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc2501d",
   "metadata": {},
   "source": [
    "# AWS - Customer story\n",
    "\n",
    "## Airbnb\n",
    "- Airbnb is an online marketplace where guests and hosts can connect with each other and share accommodations\n",
    "\n",
    "<img src=\"images/airbnb_AWS_architecture.png\">\n",
    "\n",
    "**Challenges solved by business architecture**\n",
    "- it runs on own multi-tenant Kubernetes clusters on EC2\n",
    "- its owned because at times a back port fixes are required or add new features into Kubernetes \n",
    "- challenges faced in the past were\n",
    "  - there are many different pods that run on a single host\n",
    "  - fine grained access controls or fine grained IAM roles are needed to these pods\n",
    "- currently\n",
    "  - the control plane runs on one of EC2\n",
    "  - the control plane runs on a physically separate EC2 host than all worker nodes\n",
    "  - the control plane manages all the pods in cluster\n",
    "  - the control plane injects service account tokens into the pods\n",
    "    - these tokens are cryptographically signed and contain an identity\n",
    "    - tokens will have namespace that pod belong to and name of the pod\n",
    "  - the pod can then take this token and send it directly to STS for verification\n",
    "  - STS can verify if the token is valid \n",
    "  - STS can then check IAM role and verify the namespace and name of the pod being requested is correct\n",
    "  - if properly checked out, will give IAM credentials and send those credentials back to the pod\n",
    "  \n",
    "**From multitenant perspective, how are the pods secured in more clustered manner in Kubernetes cluster?**\n",
    "- each pod has its own identity that is provided by the control plane\n",
    "- in the IAM role definition, the service owners are able to verify the roles XYZ should be allowed to be assumed by pods in XYZ namespace\n",
    "- given the connection with each other, it can be guaranteed that other pods and different namespaces cannot assume XYZ IAM role\n",
    "\n",
    "**In terms of reconciliation and making sure that the pods are assuming the right role, how are they monitored and audited?**\n",
    "- STS emits events into the CloudTrail, whenever it creates new tokens and also when the pods are assumed to an new IAM role \n",
    "- these events are then ingesteed into Elasticsearch cluster\n",
    "- an engineeer can then see \n",
    "  - when a pod is assuming an IAM role, \n",
    "  - what IAM rolees are being used\n",
    "  - can see when a failure happens, and when that happens before service owner knows, \n",
    "    - check definition of their IAM role to make sure the correctness\n",
    "    - alert the service owner automatically\n",
    "\n",
    "\n",
    "<img src=\"https://www.codekarle.com/images/Airbnb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f807c79",
   "metadata": {},
   "source": [
    "## SSB Cargo: Data collection and processing with serverless analytics services\n",
    "\n",
    "- SSB - Swiss Federal Railway company\n",
    "- freight company\n",
    "\n",
    "**What is the project**\n",
    "- earlier the freight train has to be physically inspected, took lot of time, goal is to reduce the time\n",
    "- sensors are put in on the train and along the track\n",
    "- focus on critical parts to do inspection quickly\n",
    "\n",
    "**Architecture**\n",
    "- Producer is the locomotive that sends lot of data, 3 million samples a day\n",
    "- Lambda takes this data and forards it to Kinesis\n",
    "- 3 million samples is filtered by Kinesis Analytics and forwards it into Kinesis stream\n",
    "- this data is then sent to lambda and then it gets pushed in the right format into DynamoDB\n",
    "- A consumer can be an algorithm, which is deciding if this train is in good condition or not\n",
    "- Consumer asks for this data from API gateway interface\n",
    "- this data is sent from the DynamoDB through Lambda to the consumer\n",
    "- Lambda manages the different formats of data into the system, enabling different pipelines \n",
    "\n",
    "**Why was other business solution as EC2 not considered?**\n",
    "- goal of this project priorities was to have minimal operations\n",
    "\n",
    "<img src=\"images/ssb_AWS_arch.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e463ecc",
   "metadata": {},
   "source": [
    "## Disney+ scales globally on Amazon DynamoDB\n",
    "- **Introduction**\n",
    "  - What is Disney+\n",
    "    - video streaming service\n",
    "    - content discovery team is responsible for APIs that serve the content metadata for Disney+ application\n",
    "    - metadata around the videos\n",
    "    - launched in Nov 2019\n",
    "    - 3 billion requests to content APIs  a day\n",
    "    - tens of TB of content metadata a day\n",
    "    - hundreds of TB of images a day\n",
    "    - hundreds of millions of recommendations per day, inserted into DynamoDB\n",
    "- **DynamoDB use cases (architecture)**\n",
    "  - **watchlist**\n",
    "    - backed by a global table\n",
    "    - simple, a service infrnt of global DynamoDB table, which lets us query watchlist related tables\n",
    "    - sync across all regions, low latency\n",
    "  - **bookmarks**\n",
    "    - start watching a video, pause it, then pick it up from you left, or start it on another device\n",
    "    - while a user watches video, the app sends stream of bookmark data to a telemetry service at the nearest AWS region to the video player\n",
    "    - that service takes bookmark data, writes it to a Kinesis stream, then read that data from Kinesis stream and insert it into global DynamoDB table that exists in the regions wheree the content API is deployed to\n",
    "    - client then requests that bookmark data from one of the content API services, when they load up homepage or movie page\n",
    "    - such architecture allows to decouple where the bookmarks is read from to where the clients are served the bookmark data from\n",
    "    - this can be deployed to any number of regions just by adding region to global DynamoDB table\n",
    "  - **recommendations**\n",
    "    - ML team generates recommendations and writes it into Kinesis stream in a single region\n",
    "    - the stream from Kinesis is read and placed into DynamoDB global table\n",
    "    - this is then used in any region using content API\n",
    "    - DynamoDB takes care of replication\n",
    "  - **content caching**\n",
    "    - DynamoDB is not used in this use case, a different datastore is used\n",
    "    - DynamoDB is used to cache the results of queries, that is used to run against the document data store\n",
    "    - this is cached with a TTL (time-to-live)\n",
    "    - basic use case is \n",
    "      - when a user query for some piece/set of content, DynamoDB cache is checked \n",
    "      - if its missing or its expired based on TTL \n",
    "      - pull from primary datastore, put it into cache\n",
    "      - serve it out from there\n",
    "      - helps to buffer request to primary data store\n",
    "- **TakeAways**\n",
    "  - **on occasions like failovers or planned maintenance, regions are evacuated** \n",
    "    - move to a different region to maintain reliability and performance of service\n",
    "    - replication that DynamoDB offers with latencies are of very low digit seconds\n",
    "    - allows to shift traffic\n",
    "  - **when Disney+ is launched in new countries**\n",
    "    - can leverage additional AWS region\n",
    "    - just by adding it to DynamoDB global table\n",
    "  - **scaling - recommendations and bookmarks volume growth**\n",
    "    - DynamoDB grows along with user base\n",
    "    - very little operational overhead\n",
    "  - **on-demand vs provisioned mode**\n",
    "    - ability to switch back and forth between on-demand mode or provision mode\n",
    "    - helps launching in new country when volume capacity is unknown\n",
    "  - **pre-partioning**\n",
    "    - DynamoDB partitions data as data storage grows, as throughput grows\n",
    "    - the number of partition grows as well, to maintain a high level of throughput\n",
    "    - on launch day 1, a large influx of bookmark data was expected\n",
    "    - into an empty table\n",
    "    - if it wasn't partitioned beforehand, to meet the demands of that scale, would have experienced throttles\n",
    "    - to meet the anticipated demand of read and write throughput about throttles, tables were pre-partitioned prior to launch\n",
    "    - a provisioned thoroughput write value was set\n",
    "    - allowing DynamoDB to partition based on that\n",
    "    - and then was switched back to on-demand mode prior to launch\n",
    "    - thus was able to avoid throttles on those tables\n",
    "  - **supporting concentrated read traffic**\n",
    "    - an items living in a partition has its own limits on read/write\n",
    "    - in content cache, some contents are more popular than other\n",
    "    - this can result in disproportionate lookups to a partition, which then results in throttle\n",
    "    - to resolve this, a strategy of appending a sequence number to the end of key was used\n",
    "    - this data was written to more than one entry\n",
    "    - on a request to any content, a GUID would be used on the request, and then hash that to one of the sequence number\n",
    "    - this is then used for the key lookup\n",
    "    \n",
    "    \n",
    "<p align=\"center\"><img src=\"./images/disneyplus_watchlist.png\" width=400 height=400></p>\n",
    "\n",
    "$\\tiny{\\text{YouTube - Disney+ - Watchlist}}$   \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/disneyplus_bookmark.png\" width=400 height=400></p>\n",
    "\n",
    "$\\tiny{\\text{YouTube - Disney+ - Bookmark}}$   \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/disneyplus_recom.png\" width=400 height=400></p>\n",
    "\n",
    "$\\tiny{\\text{YouTube - Disney+ - Recommendation}}$   \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/disneyplus_contentCache.png\" width=400 height=400></p>\n",
    "\n",
    "$\\tiny{\\text{YouTube - Disney+ - Content Caching}}$   \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/disneyplus_supprtConcReadTraffic.png\" width=400 height=400></p>\n",
    "\n",
    "$\\tiny{\\text{YouTube - Disney+ - Supporting Concentration Read Traffic}}$   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
