{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4958beb",
   "metadata": {},
   "source": [
    "# Netflix creativity\n",
    "\n",
    "## [System Architecture for Personalization and Recommendation](https://netflixtechblog.com/system-architectures-for-personalization-and-recommendation-e081aa94b5d8)\n",
    "\n",
    "### Online Computation\n",
    "- subject to SLA with maximum latency to respond recommendation\n",
    "- fallback mechanism of precomputed result is adopted in case of failures\n",
    "- computational expensive\n",
    "\n",
    "### Offline computation\n",
    "- less limitation on latency, providing more choices to complex algorithms\n",
    "- aggregate stats periodically\n",
    "- new algorithms testing \n",
    "- allows focus on experiments than optimization\n",
    "\n",
    "### Nearline computation\n",
    "- intermediate compromise between two modes\n",
    "- allows system to be more responsive\n",
    "- sandbox for applying incremental learning algorithms\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*qqTSkHNOzukJ5r-b54-wJQ.png\" title=\"\" width=500 height=500></p>\n",
    "\n",
    "### ways to combine these 3 approaches\n",
    "- fallback\n",
    "- partial precomputation in offline mode allowing less costly operation in online mode\n",
    "- modeling can be done in hybrid offline/online manner \n",
    "  - use case of Matrix Factorization calculation \n",
    "    - can be done in hybrid online/offline way\n",
    "    - some factors can be precomputed offline while others updated in real-time\n",
    "  - use case of unsupervised clustering \n",
    "    - offline computation of cluster centers \n",
    "    - online assignment of clusters\n",
    "\n",
    "\n",
    "### Offline Jobs\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*cwfWTmdtk0Z6pOl9uVU0JA.png\" width=500 height=500></p>\n",
    "\n",
    "\n",
    "- scheduled periodic jobs\n",
    "- two primary types \n",
    "  - model training\n",
    "    - collect data\n",
    "    - apply ML algo\n",
    "    - online learning techniques also possible\n",
    "  - batch computation of intermediate or final results\n",
    "- these queries run over large amounts of data\n",
    "  - run on Hadoop via Hive or Pig jobs\n",
    "  - once completed, publish results and notify subscribers\n",
    "  - support different repo as HDFS, S3, Cassandra\n",
    "  - handle errors, allow monitoring\n",
    "- this is supported using internal tool called **Hermes** \n",
    "  - this covers use cases similar to Apache Kafka, but is not a message/event queue system\n",
    "\n",
    "### Signals and Models\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*8lw3s6XZxOUTGM0yVJLJxA.png\" width=500 height=500></p>\n",
    "\n",
    "- In all modes either online or offline computation, three type of inputs are required - models, data, and signals\n",
    "  - Models - small parameter files that have been previously trained offline\n",
    "  - Data - is previously processed information stored in database, such as movie metadata or popularity \n",
    "  - Signals - refer to information inputed to algorithm obtained from live services and other user-related information such as watch history, or context data such as session, device, date, or time\n",
    "\n",
    "\n",
    "### Event and Data Distribution\n",
    " \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*dzpP6wfwejPQ-xKUDJlukg.png\" width=500 height=500></p>\n",
    "\n",
    "- goal: translate interaction data into insights\n",
    "- source: \n",
    "  - user interface such as smart TVs, tablets, game consoles\n",
    "  - user events such as click, browses, viewing history\n",
    "- events: time sensitive information\n",
    "- data: dense information where latency is not concern\n",
    "- near-real-time event flow is managed through an internal framework called **Manhattan**, similar to Twitter Storm\n",
    "  - data flow is managed through logging through Chukwa to Hadoop \n",
    "  - Hermes is used for publish-subscribe mechanism\n",
    "\n",
    "\n",
    "### Recommendation results\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*Y1oZvmQnwc7lJTL07Q4eXg.png\" width=500 height=500></p>\n",
    "\n",
    "- goal: personalized recommendations\n",
    "  - mostly offline algorithms are applied\n",
    "  - freshness applied using online algorithms real-time signals\n",
    "\n",
    "- offline and intermediate results stored in Cassandra, EVCache, and MySQL\n",
    "  - MySQL allows storage of structured relational data \n",
    "    - not scalable  in distributed environments\n",
    "  - Cassandra and EVCache both provide key-value stores \n",
    "  - Cassandra is a standard solution for distributed and scalable no-SQL store \n",
    "  - Cassandra works well generally\n",
    "    - however for intensive and constant write operations, EVCache gives better performance\n",
    "- optimal solution is required to handle conflicting goals of query complexity, read/write latency, and transactional consistency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0218570",
   "metadata": {},
   "source": [
    "## [Rapid Event Notification System (RENO)](https://netflixtechblog.com/rapid-event-notification-system-at-netflix-6deb1d2b57d1)\n",
    "- To maintain real time experience, RENO facilitates server initiated communication in scalable and extensible manner\n",
    "- the system works asynchronously that supports both online and offline computation\n",
    "- seemless experience across platforms and devices\n",
    "- requires more than traditional request-response model\n",
    "- Use cases\n",
    "  - viewing activity, \n",
    "  - personalized experience refresh\n",
    "  - membership plan changes\n",
    "  - profile changes\n",
    "- Design decisions\n",
    "  - Single Events Source\n",
    "    - listen for events from different microservices\n",
    "    - real time event flow is managed by Manhattan project\n",
    "    - Manhattan project - event management framework\n",
    "  - Event prioritization\n",
    "    - wide ranging use cases\n",
    "    - segmented event processing\n",
    "    - different events and traffic will have different priority\n",
    "  - Hybrid Communication Model\n",
    "    - key challenge is to support multiple platforms\n",
    "    - a pull model would result in chatty applications\n",
    "    - a push model would result in missing notifications\n",
    "    - hybrid is the best solution\n",
    "  - Targeted Delivery\n",
    "    - device specific notification delivery\n",
    "    - limits outgoing traffic footprint\n",
    "  - Managing High RPS\n",
    "    - at peak times, serves 150k events/second\n",
    "    - thundering herd problem\n",
    "      - large number of processes/threads waiting for an event are awoken, but only one process is able to handle the event\n",
    "      - results in system freeze\n",
    "    - few optimizations\n",
    "      - event age filter\n",
    "      - notifications to online devices only, using Zuul\n",
    "      - to keep thresholds under threshold, aggressive cluster scale-up configurations\n",
    "      - merge duplicate events \n",
    "      \n",
    "- RENO service is broken into following components:\n",
    "  - Event triggers\n",
    "  - Event Management Engine\n",
    "  - Event Priority Based Queue\n",
    "  - Event Priority Based Clusters\n",
    "  - Outbound Messaging System\n",
    "  - Persistent Store (Cassandra)\n",
    "  \n",
    "- RENO is the centralized rapid notification service for all Netflix products\n",
    "      \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*i6o12AqlvqZDMcAj\" width=500 height=500></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e8cd9",
   "metadata": {},
   "source": [
    "## Netflix Recommendations\n",
    "- Netflix Prize - 2006 - improve accuracy by 10%, earlier was Cinematch\n",
    "- beat existing Netflix RMSE of 0.9525 to 0.8572 or less\n",
    "- Korbell team - Progress Prize 8.43% improvement - 107 algorithms - 2000 hours of work\n",
    "- 2 algorithms with best performance \n",
    "  - Matrix Factorization or the Singular Value Decomposition SVD \n",
    "  - Restricted Boltzmann Machines (RBM)\n",
    "  - SVD resulted in RMSE of 0.8914 \n",
    "  - RBM resulted in RMSE of 0.8990 \n",
    "  - a linear blend reduced the error to 0.88\n",
    "- 75% of people follow recommendations\n",
    " \n",
    "\n",
    "- Type of personalization\n",
    "  - Diversity - suited as per family member \n",
    "  - Awareness - adapt to the change in taste\n",
    "  - Explanations - friends watch history, explicit taste preferences and ratings\n",
    "  - Genre collections, subsets within genre, ranking of those titles\n",
    "  - Freshness - Most popular, Top rated\n",
    "  - Similarity - More like 'XYZ'\n",
    "  - Ranking \n",
    "  \n",
    "- Goal: rank attractive items \n",
    "- Learning to rank\n",
    "  - application of ML (supervised, semisupervised, RL), to construct ranking models for information retrieval systems\n",
    "  - supervised classification methods are used for ranking\n",
    "    - Logistic Regression, \n",
    "    - Support Vector Machines, \n",
    "    - Neural Networks, or \n",
    "    - Decision Tree-based methods \n",
    "        - Gradient Boosted Decision Trees (GBDT)\n",
    "    - RankSVM or RankBoost.\n",
    "\n",
    "- commonly used ml algorithms\n",
    "  - Linear regression\n",
    "  - Logistic regression\n",
    "  - Elastic nets\n",
    "  - Singular Value Decomposition\n",
    "  - Restricted Boltzmann Machines\n",
    "  - Markov Chains\n",
    "  - Latent Dirichlet Allocation\n",
    "  - Association Rules\n",
    "  - Gradient Boosted Decision Trees\n",
    "  - Random Forests\n",
    "  - Clustering techniques from the simple k-means to novel graphical approaches such as Affinity Propagation\n",
    "  - Matrix factorization\n",
    "\n",
    "\n",
    "- A/B testing (bucket testing)\n",
    "  - how to integrate our machine learning approaches into this data-driven A/B test culture\n",
    "    - an offline-online testing process\n",
    "      - offline testing cycle is a step where we test and optimize our algorithms prior to performing online A/B testing\n",
    "        - to measure model performance in offline mode using\n",
    "          - track ranking measures such as \n",
    "            - normalized discounted cumulative gain, \n",
    "            - mean reciprocal rank, or \n",
    "            - fraction of concordant pairs, \n",
    "          - track classification metrics such as \n",
    "            - accuracy, \n",
    "            - precision, \n",
    "            - recall, or \n",
    "            - F-score\n",
    "        - measure famous RMSE from the Netflix Prize \n",
    "        - or other more exotic metrics \n",
    "        - track how well these metrics correlate to measurable online gains in our A/B tests\n",
    "        - since mapping is not perfect, offline performance is used only as an indication to make informed decisions on follow up tests\n",
    "      - after validating offline testing hypothesis, launch A/B test  \n",
    "     \n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/max/1400/1*30KWZ38MzCXDB9AXjMtGjA.png\" title=\"https://miro.medium.com/\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*i1g98589DuVhbKDqyIhl1w.png\" title=\"https://miro.medium.com/\" width=300 height=300></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5175f62",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"./images/netflixPrice.png\" width=500 height=500></p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f9cdb",
   "metadata": {},
   "source": [
    "## Personalization algorithms\n",
    "- Different household members will have different tastes\n",
    "- Optimize both accuracy and diversity\n",
    "- Adapt to the taste, which encourages trust in the system\n",
    "- connected with Facebook which gives personalization algorithm generate recommendations based on social circle\n",
    "- genre personalization\n",
    "  - choice of genre\n",
    "  - subset of titles within that genre\n",
    "  - ranking among those titles\n",
    "- freshness and diversity\n",
    "- Similarity is another personalization\n",
    "  - most popular, \n",
    "  - top rated, \n",
    "  - based on your taste preferences\n",
    "  - similar titles\n",
    "  - more like \"title watched\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb0c79",
   "metadata": {},
   "source": [
    "## Caching at Netflix\n",
    "\n",
    "- https://www.slideshare.net/ShashiShekarMadappa/evcache-at-netflix\n",
    "- https://www.linkedin.com/in/shashishekar/#experience\n",
    "\n",
    "- highly scalable memcache-based caching solution called as **EVCache**(Ephemeral Volatile Cache)\n",
    "- a memcached & spymemcached based caching solution\n",
    "- **Why caching?**\n",
    "  - fast: faster response time\n",
    "    - use case: HomePage - algorithm needs to know Users Taste, Movie Viewing History, Queue, Rating, etc\n",
    "  - shared: allows session based app to be stateless without sessions in cloud\n",
    "  - scalable: allows NoSQL based persistence like Cassandra/SimpleDB/S3\n",
    "  \n",
    "- **Overview**\n",
    "  - distributed Key-Value store - spread across multiple instances\n",
    "  - AWS Zone-Aware and data can be replicated across zones.\n",
    "  - registers and works with Netflix’s internal Naming Service for automatic discovery of new nodes/services.\n",
    "  - stores the data in key-value format\n",
    "    - Key has to be a non-null String and value can be a non-null byte-array, primitives, or serializable object \n",
    "    - Value should be less than 1 MB\n",
    "  - As a generic cache cluster that can be used across various applications, it supports an optional Cache Name, to be used as namespace to avoid key collisions\n",
    "  - Typical cache hit rates are above 99%\n",
    "  - Works well with Netflix Persister Framework for e.g., In-memory -> backed by EVCache -> backed by Cassandra/SimpleDB/S3\n",
    "  \n",
    "- **Elasticity and deployment ease:**\n",
    "  - linearly scalable\n",
    "  - monitor capacity \n",
    "  - can add capacity within a minute and potentially re-balance and warm data in the new node within a few minutes\n",
    "  \n",
    "- **Latency:** \n",
    "  - response time in low milliseconds\n",
    "  - Reads from EVCache are typically served back from within the same AWS zone\n",
    "  \n",
    "- **Single Zone Deployment:**\n",
    "  - scenario: AWS US-EAST Region and Zone-A where an EVCache cluster with 3 instances has a Web Application performing CRUD operations (on the EVcache system)\n",
    "    - Upon startup, an EVCache Server instance registers with the Naming Service\n",
    "    - During startup of the Web App, the EVCache Client library is initialized which looks up for all the EVCache server instances registered with the Naming Services and establishes a connection with them\n",
    "    - When the Web App needs to perform CRUD operation for a key the EVCache client selects the instance on which these operations can be performed. Consistent Hashing is used to shard the data across the cluster\n",
    "    \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*oBCJjtUw80I8O5CO3zZ4Mg.png\" width=500 height=500></p>\n",
    "\n",
    "- **Multi Zone Deployment:**\n",
    "  - scenario: replication across multiple zones in AWS US-EAST Region. It has an EVCache cluster with 3 instances and a Web App in Zone-A and Zone-B\n",
    "    - Upon startup, an EVCache Server instance in Zone-A registers with the Naming Service in Zone-A and Zone-B\n",
    "    - During startup of the Web App in Zone-A, the Web App initializes the EVCache Client library which looks up for all the EVCache server instances registered with the Naming Service and connects to them across all zones\n",
    "    - When the Web App in Zone-A needs to read the data for a key, the EVCache client looks up the EVCache Server instance in Zone-A which stores this data and fetches the data from this instance\n",
    "    - When the Web App in Zone-A needs to write or delete the data for a key, the EVCache client looks up the EVCache Server instances in Zone-A and Zone-B and writes or deletes it\n",
    "\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*xPIXw-Lufyqy2JCIVpRu6A.png\" width=500 height=500></p>\n",
    "\n",
    "\n",
    "- **Case study: Movie and TV show similarity**\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*4qVbkm-lCUT3V11p.\" width=500 height=500></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad3e96",
   "metadata": {},
   "source": [
    "## Netflix components\n",
    "### Netflix on cloud\n",
    "  - AWS\n",
    "    - components that dont involve video streaming\n",
    "  - OpenConnect\n",
    "    - use it for video streaming\n",
    "    - OpenConnect is Netflix's proprietary CDN - Content Delivery Network\n",
    "      - CDN - network of distributed servers\n",
    "      - distributed across geographies for low latency\n",
    "      - maintained by Netflix\n",
    "  \n",
    "<p align=\"center\"><img src=\"./images/netflix_system_design.png\" width=500 height=500></p>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402189d7",
   "metadata": {},
   "source": [
    "### How does Netflix support different clients\n",
    "  - all the apps are written using platform specific code\n",
    "  - Netflix web app is written using React.js\n",
    "  - why React.js?\n",
    "    - startup speed\n",
    "    - run time performance\n",
    "    - modularity\n",
    "- How does Netflix load balancing work\n",
    "  - uses Amazon's Elastic Load Balancer ELB service to different front-end instances/services\n",
    "  - ELB is configured so that load is first balanced across the zones and then instances\n",
    "  - 2-tier balancing scheme\n",
    "  - first tier consists of DNS based round-robin balancing across different zones\n",
    "  - zones are logical grouping of servers\n",
    "  - second tier is an array of instances which does round-robin load balancing across instances \n",
    "  \n",
    "  \n",
    "<p align=\"center\"><img src=\"./images/netflixLoadBalancer.png\" width=400 height=400></p>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71f42f",
   "metadata": {},
   "source": [
    "### How Netflix onboards video\n",
    "  - lot of preprocessing\n",
    "    - converting videos into different resolutions\n",
    "    - this process is called transcoding\n",
    "      - optimization for particular type of device\n",
    "      - each format is of different resolutions\n",
    "  - a video is broken into \n",
    "  - it also file optimize for different network\n",
    "    - depending on fast or slow bandwidth, resolution and format will be different\n",
    "    - adaptive bitrate steaming\n",
    "      - where if the bandwidth improves/deteriorate, the experience/streaming will switch accordingly\n",
    "  - multiple copies of same movie is saved across different geography of different format/resolution\n",
    "    - more than 1000 copies are made for each movie\n",
    "  - uses lot of parallel workers\n",
    "    - breaks movie into different pieces/chunks and puts into a queue\n",
    "    - pieces from the queue will then be picked from different workers\n",
    "    - workers will then merge these clips and place them into Amazon S3\n",
    "  \n",
    "  \n",
    "<p align=\"center\"><img src=\"./images/netflixOC.png\" width=600 height=600></p>  \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflixTranscoding.png\" width=600 height=600></p>  \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflixVideoStreaming.png\" width=400 height=400></p>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325c06d",
   "metadata": {},
   "source": [
    "### How does OpenConnect work\n",
    "  - all the different formats are uploaded into OC \n",
    "  - when user makes request\n",
    "    - based on the AWS data centers, models, \n",
    "\n",
    "\n",
    "- OpenConnect delivers 100% of Netlix video traffic\n",
    "- 235 million hours of streaming per day\n",
    "- simultaneous peak traffic, making Netflix Open Connect, highest-volume networks in the world\n",
    "\n",
    "- close to 90% of Netflix's traffic is delivered via direct connections between Open Connect and the residential Internet Service Providers (ISPs)\n",
    "- these are localized to the regional point of interconnection that’s geographically closest to Netflix member\n",
    "- using installed Open Connect Appliances (OCAs) in an ISP’s data center, almost all Netflix content is served from the local OCAs rather than “upstream” from the internet\n",
    "  - dual benefit of reducing the ISP’s cost of operation and ensuring best possible Netflix experience for their subscribers\n",
    "- OCA in 1000 separate locations around the world  \n",
    "\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflix_isp_cdn.png\" width=400 height=400></p>  \n",
    "\n",
    "\n",
    "**New Content**\n",
    "- a new content goes through various preprocessing, encoding, bitrates, subtitles and other quality enhancements\n",
    "- deployed to AWS Simple Storage Service (S3) \n",
    "- then these are deployed to Open Connect Appliances (OCAs)\n",
    "\n",
    "**Proactive Caching**\n",
    "- can predict with high accuracy what members will watch and at what time of day \n",
    "- upload contents to OCAs during non-peak hours bandwidth\n",
    "- this optimizes disk efficiency by avoiding read/write contention\n",
    " \n",
    "**OCA Clusters**\n",
    "\n",
    "**Minimizing network distance**\n",
    "- Open Connect global CDN consists of servers that are either physically located in ISP data centers (ISP servers) or IXP data centers (IX servers)\n",
    "- aims to transmit content across shortest networking path, maximizing members streaming experience\n",
    "- popularity content ranked by country, region, or other selection criteria are distributed into manifest clusters\n",
    "- OCAs are grouped into manifest clusters, to distribute one or more copies of the catalog, depending on the popularity of the title\n",
    "\n",
    "**Maximizing traffic by minimizing inter-server traffic variance**\n",
    "- uses consistent hashing\n",
    "- results in well balanced cluster\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*7Dja7NTcH0UQhfL427L2lg.png\" width=500 height=500></p>\n",
    "\n",
    "**Content organization**\n",
    "- 1200 files of content for one episode of The Crown\n",
    "- by title, encoding profile, bitrate, language\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1170/1*FMvFhiNp0i68ppOuDDUKyg.png\" width=500 height=500></p>\n",
    "\n",
    "\n",
    "**Per title encoding optimization**\n",
    "\n",
    "\n",
    "**Adaptive streaming algorithms**\n",
    "- bitrate-resolution pairs (bitrate ladder)\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1266/1*tCdB8E0X6zDJKAhpTLxNBA.png\" width=200 height=200></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8aeb8",
   "metadata": {},
   "source": [
    "### Why Zuul\n",
    "  - handles request from devices and websites to backend of streaming application\n",
    "  - supports dynamic routing to different backend clusters\n",
    "  - supports monitoring and route requests to multiple Amazon scaling services\n",
    "  - supports authentication and security\n",
    "  - helps in gauging performance while stress testing, by increasing traffic to a particular cluster\n",
    "  - load shedding\n",
    "  - multi region resiliency - routing requests across AWS regions\n",
    "\n",
    "\n",
    "> The following are the key characteristics of a Zuul Filter:  \n",
    "> * Type: most often defines the stage during the routing flow when the Filter will be applied (although it can be any custom string)  \n",
    "> * Execution Order: applied within the Type, defines the order of execution across multiple Filters  \n",
    "> * Criteria: the conditions required in order for the Filter to be executed  \n",
    "> * Action: the action to be executed if the Criteria is met  \n",
    "\n",
    "  \n",
    "> There are several standard Filter types that correspond to the typical lifecycle of a request:  \n",
    "> * PRE Filters execute before routing to the origin. Examples include request authentication, choosing origin servers, and logging debug info.  \n",
    "> * ROUTING Filters handle routing the request to an origin. This is where the origin HTTP request is built and sent using Apache HttpClient or Netflix Ribbon.  \n",
    "> * POST Filters execute after the request has been routed to the origin. Examples include adding standard HTTP headers to the response, gathering statistics and metrics, and streaming the response from the origin to the client.  \n",
    "> * ERROR Filters execute when an error occurs during one of the other phases\n",
    "\n",
    "\n",
    "- Summary\n",
    "  - Netty handlers handles the inward/outward messaging into the network protocol, web server, connection management and proxying\n",
    "  - Inbound filters run before proxying the request and is used for authentication, routing, or decorating request\n",
    "  - Endpoint filters is used to return static response or proxy request to backend service\n",
    "  - Outbound filters are applied after a response has been returned for gzipping, or handling metrics or customizing headers\n",
    "  \n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflixZuul.png\" width=400 height=400></p>  \n",
    "\n",
    "- https://qconnewyork.com/ny2018/presentation/architectures-youve-always-wondered-about-presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0bf6",
   "metadata": {},
   "source": [
    "### Why Hystrix\n",
    "- Netflix uses microservices architecture\n",
    "- there is a dependency of quick throughput of these services to respond quickly\n",
    "- critical services are identified to prevent cascading service failure\n",
    "- each service is configured a set timeout withing which it needs to respond back\n",
    "- Netflix's stateless microservices architecture helps in routing the service request if it does not respond in timely fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffdbe10",
   "metadata": {},
   "source": [
    "### Why EVCache\n",
    "\n",
    "- [Caching at Netflix (above)](#Caching-at-Netflix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8cd60c",
   "metadata": {},
   "source": [
    "### Why Mantis\n",
    "- https://netflixtechblog.com/open-sourcing-mantis-a-platform-for-building-cost-effective-realtime-operations-focused-5b8ff387813a\n",
    "\n",
    "- track events in real time at device specific granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f28f3",
   "metadata": {},
   "source": [
    "### Why Big Data\n",
    "- facilitates algorithms and analytics\n",
    "- use Hadoop, Hive, Pig, Parquet, Presto, Spark\n",
    "- use Genie is a powerful, REST-based abstraction to data processing frameworks, notably Hadoop\n",
    "- Inviso provides detailed insights into performance of Hadoop jobs and clusters\n",
    "- Lipstick provides visual workflow representation of Pig jobs\n",
    "- Aegisthus enables bulk abstraction of data out of Cassandra for downstream analytic processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb701371",
   "metadata": {},
   "source": [
    "### Manhattan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae3204",
   "metadata": {},
   "source": [
    "### Why Titus\n",
    "- container management platform\n",
    "- tight integration between Titus and both Amazon and Netflix infrastructure\n",
    "\n",
    "\n",
    "> Titus aims to enable easy and reliable deployment of containerized batch and service applications. Achieving this goal requires:\n",
    "> - Allowing containerized applications to seamlessly interact with AWS, Netflix, and other cloud services. Interactions with other systems should not be an application burden simply because it is running in a container.\n",
    "> - Operability to ensure the system is capable of running mission critical workloads and meeting SLAs.\n",
    "> - Scalability to run tens of thousands of containers on top of thousands of hosts across a variety of use cases.\n",
    "\n",
    "<p align=\"center\"><img src=\"https://netflix.github.io/titus/images/titus-arch.png\" width=500 height=500></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac420e",
   "metadata": {},
   "source": [
    "### Why Papermill\n",
    "- Schedule Notebooks at Netflix\n",
    "- Which single tool can data scientist, data engineer, and machine learning engineer work on?\n",
    "  - Jupyter notebook\n",
    "    - managed JSON documents with a simple interface to execute code within\n",
    "    - uses Jupyter protocol\n",
    "  - Papermill \n",
    "    - nteract library built for configurable and reliable execution of notebooks in production ecosystems\n",
    "    - it takes notebook path and input parameters, executes the requested notebook, and saves the resulting artifact to another output notebook\n",
    "    - doesn’t modify the source notebook\n",
    "    - as output notebooks are isolated records, it can be used by users in isolation for debugging or creating new templates\n",
    "    - as it controls its own runtime processes, maintainence of notebook kernels is not required\n",
    "\n",
    "\n",
    "- Overview of nteract's Papermill library\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*QLer52L9p-T72bGW\" width=500 height=500></p>\n",
    "\n",
    "- Deeper look at Papermill library\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*058TIxB_YEFxmUDy\" width=500 height=500></p>\n",
    "\n",
    "**Scheduling Notebooks**  \n",
    "\n",
    "- Running scheduled notebooks on Docker containers\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*byeqo-pBXVPU6xjq\" width=500 height=500></p>\n",
    "\n",
    "- Run integration tests with Papermill\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*j6RNZN-IO3fXW-Ff\" width=500 height=500></p>\n",
    "\n",
    "**Notebook infrastructure at Netflix**\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*WOEEJizYnO8ibtU2l9jWbA.jpeg\" width=500 height=500></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73c394",
   "metadata": {},
   "source": [
    "## Data at a glance (as in Oct 2017)\n",
    "- launched in 1997\n",
    "- 125+ million hours watched every day\n",
    "  - peak - 250+ million hours/a day\n",
    "- 130 countries worldwide\n",
    "- 4000 different devices\n",
    "- 700+ billion events written/every day\n",
    "  - peak - a trillion events/a day\n",
    "- 60+PB in data warehouse\n",
    "- grows at a rate of 300TB DW writes/per day\n",
    "- on average 5PB DW reads\n",
    "\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflix_eventsArch.png\" width=400 height=400></p>\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflix_pullData.png\" width=400 height=400></p>\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflix_pushData.png\" width=400 height=400></p>\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/netflix_typeofengineers.png\" width=300 height=300></p>\n",
    "\n",
    "**N Takeaways**\n",
    "- \"**Expecting failure** is more efficient than trying to **prevent failure**\"\n",
    "- \"**Stale data** is almost always preferred over **unfortunate data**\"\n",
    "- \"Delivering **high quality** analytics is really, **really difficult** to do well\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed21f5e",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "- \"Making decisions is easy - what's hard is making the right decisions\"\n",
    "- split sample into two groups\n",
    "  - Group A - control group - uses base Netflix experience\n",
    "  - Group B - treatment group - based on specific hypothesis\n",
    "- some metrics are specific to hypothesis\n",
    "- monitor variants of new feature \n",
    "- individuals in two groups are on average balanced on all dimensions\n",
    "  - random assignments ensures for example average length of membership is not markedly different\n",
    "- If there’s a positive change, or no evidence of any meaningful change, the new experience is adapted; if there’s evidence of a negative change, prior product experience is rolled back\n",
    "- A/B tests helps make causal analysis\n",
    "- Running A/B tests allows substantiate causality and confidently make changes to the product knowing that customers have voted positively for their actions\n",
    "- With the Top 10 example, the hypothesis read: “Showing members the Top 10 experience will help them find something to watch, increasing member joy and satisfaction.” \n",
    "\n",
    "### Interpreting A/B test results: false positives and statistical significance\n",
    "- If a test shows a statistically significant improvement in primary decision metric, the feature is a strong candidate for a roll out\n",
    "- no approach to decision making can entirely eliminate uncertainty and the possibility of making mistakes\n",
    "- two types of error\n",
    "  - false positive (Type I error) occurs when data from the test indicates meaningful difference between control and treatment experiences, but in truth there is no difference\n",
    "    - a medical test shows result as positive for a disease when patient is healthy\n",
    "  - false negative (Type II error), occurs when data do not indicate a meaningful difference between control and treatment, but in reality there is a difference\n",
    "    - a medical test shows result as negative — when patient is unhealthy\n",
    "- two concepts in A/B testing that are closely related to p-value\n",
    "  - rejection region for a test\n",
    "  - confidence interval for an observation\n",
    "- TODO more\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*8d7ysHOGOLop7xU4dBY_RQ.gif\" width = 500 height= 500></p>\n",
    "\n",
    "### Interpreting A/B test results: false negatives and power\n",
    "- Label the photo of cat as \"not cat\"\n",
    "- TODO more\n",
    "\n",
    "### Power of hypothesis test\n",
    "> The statistical power of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis ($H_{0}$) when a specific alternative hypothesis ($H_{1}$) is true. It is commonly denoted by $(1-\\beta)$ , and represents the chances of a \"true positive\" detection conditional on the actual existence of an effect to detect. Statistical power ranges from 0 to 1, and as the power of a test increases, the probability $\\beta$  of making a type II error by wrongly failing to reject the null hypothesis decreases.\n",
    "> - where $\\beta$ is the probability of Type 2 error (false negative)\n",
    "> - $(1-\\beta)$ is the probability of true positive, i.e. correctly rejecting the null hypothesis (power of the test)\n",
    "> - $\\alpha$ is the probability of Type 1 error (false positive)\n",
    "> - $(1-\\alpha)$ is the probability of true negative (correctly not rejecting the null hypothesis)\n",
    "\n",
    "<p align=\"center\"><img src=\"./images/significance_level_power.png\" height=300 width=300></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77635179",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e09c741f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8e8d65",
   "metadata": {},
   "source": [
    "### Cloud based Microservices architecture\n",
    "\n",
    "- https://medium.com/swlh/a-design-analysis-of-cloud-based-microservices-architecture-at-netflix-98836b2da45f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ac61f",
   "metadata": {},
   "source": [
    "### References (ToRead)\n",
    "- Chukwa\n",
    "- [Netflix Github repository](https://github.com/Netflix)\n",
    "- [Netflix Viewing Data](https://netflixtechblog.com/netflixs-viewing-data-how-we-know-where-you-are-in-house-of-cards-608dd61077da)\n",
    "- [Netflix tech blog](https://netflixtechblog.com/)\n",
    "- Spinnaker\n",
    "- Chaos Monkey\n",
    "- [concurrency-limits](https://github.com/Netflix/concurrency-limits)\n",
    "- [Netflix ML Presentation](https://www.slideshare.net/FaisalZakariaSiddiqi/linkedin-talk-at-netflix-ml-platform-meetup-sep-2019)\n",
    "- [Netflix Research]()\n",
    "- [Bandit and RL](https://netflixtechblog.com/ml-platform-meetup-infra-for-contextual-bandits-and-reinforcement-learning-4a90305948ef)\n",
    "- http://memcached.org/blog\n",
    "- https://code.google.com/archive/p/spymemcached/\n",
    "- [A/B testing - 5 part series](https://netflixtechblog.com/building-confidence-in-a-decision-8705834e6fd8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
